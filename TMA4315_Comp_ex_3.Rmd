--- 
title: "TMA4315: Compulsory exercise 3: (Generalized) Linear Mixed Models" 
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
date: "`r format(Sys.time(), '%d.%m.%Y')`"
subtitle: 'Group XX: Henrik Syversveen Lie, Mikal Stapnes, Oliver Byhring'
---

```{r setup, include = FALSE}
library(formatR)
showsol <- FALSE
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 68), tidy = TRUE, warning = FALSE, error = FALSE, message = FALSE, echo = TRUE)
library(ggplot2)
```

# a)
```{r, echo = F, eval = T}
library(GGally)
dataset <- read.table("https://www.math.ntnu.no/emner/TMA4315/2018h/jsp2.txt", header = TRUE)
indices = dataset$gender == 'boy'

mean(dataset[dataset$gender == 'boy', ]$math)
mean(dataset[dataset$gender == 'girl', ]$math)
ggpairs(data = dataset, mapping = aes(col = gender), columns = c("social", "raven", "math"), legend = 1)
```

* Comment briefly on the plot you have created

First, we see that there is a positive correlation between the `raven` (test score) and `math` variable. This is as expected. Furthermore, we see that girls perform somewhat better in the math test than boys. Also, there is no evident correlation between social class and test scores, which is somewhat surprising.


```{r, echo = F, eval = T}
fit = lm(math~raven+gender, data = dataset)
summary(fit)
```


We fit a linear model with `math` as response, and `raven` and `gender` as covariates. Model for the $k$th student:

$$Y_k=\mathbf{x}_k\boldsymbol{\beta}+\epsilon_k$$

* Explain what the different parts of this model are called.

$Y_k$ is called the response or random component, and will be the `math` score of student $k$. We assume the response to be normal distributed. The term $\mathbf{x}_k\boldsymbol{\beta}$ is the systematic component, or linear predictor. The final term $\epsilon_k$ is called the random error component, and is normal distributed with mean 0 and variance $\sigma^2$.

* Comment briefly on the parameter estimates you have found.

All parameter estimates are significant on a $0.001$ level. We observe that the coefficient $\beta_{raven} = 0.1965$ and $\beta_{girl} = 2.5381$, which means that if $x_{raven} \rightarrow x_{raven} + 1$ our model would predict an increase in the math score of $0.1965$. Similarly for `girl`, our model will predict a `math` score that is $2.5381$ higher for a girl than for a boy assuming the remaining covariates are equal. 

* What are we investigating with this model?

With this model we assume a linear relationship between the respone $Y =$ `math` and the covariates `raven` and `gender` and a normal distribution of the residuals,

$$ Y_k = x_k^T \beta + \epsilon_k, \quad \epsilon_k \sim N(0, \sigma^2) $$

Under this assumption we investigate the significance and strength of our parameters $\beta_{raven}$ and $\beta_{girl}$. We found both that the parameters are significant and that they are relatively strong. 

# b)

However, this model assumes that the distribution of `raven` and `gender` is independent of other covariates, which is not necessarily true. If there has been some gender distribution among the good and bad schools, this `school` effect will affect the parameter estimation $\beta_{gender}$ and we will not be able to distinguish what should be attributed to the gender and what to the schools. 

We therefore want to include in our model a random intercept $\gamma_{0, school}$ that seeks to remove the `school` factor as a contributing effect of the other parameters estimates. 

we fit a new model
$$\mathbf{Y}_i = \mathbf{X}_i\beta + \mathbf{1}\gamma_{0i} + \epsilon_i.$$



* Explain what the different parts of this model are called and what dimensions the model components have.

The vector $\mathbf{Y}_i$ is still the response or random component and has dimension $n_i\times1$. The term systematic component or linear predictor is now $\mathbf{X}_i\beta+\mathbf{1}\gamma_{0i}$. $\mathbf{X}_i$ is a $n_i\times p$ design matrix, $\beta$ is a $p\times1$ vector of fixed coefficients and $\mathbf{1}$ is a $n_i\times1$ vector (design matrix for random effects) with every element equal 1. $\gamma_{0i}$ is the random intercept, which is a normal distributed scalar with mean 0 and variance $\tau_0^2$. Finally, the term $\epsilon_i$ is the random error component, which is a $n_i\times1$ normal distributed vector with mean 0 and variance $I\sigma^2$.


* Write down distributional assumptions for $\gamma_{0i}$ and $\epsilon_i$.

We assume that each $\epsilon_i$ is independent, and that each of its elements are independent. This gives $\epsilon_i \sim N_{n_i}(0,I\sigma^2)$. Also, we assume $\gamma_{0i}$ i.i.d. with $\gamma_{0i} \sim N_1(0,\tau_0^2)$. 

* What do we assume about the dependency between the responses at school $i$, $\mathbf{Y}_i$, and school $k$, $\mathbf{Y}_k$?

We assume that responses between different schools $i$ and $k$ are conditionally independent. This means that if we construct a new global model for all clusters, with
$$\mathbf{Y}= \left(\begin{array}{c} 
\mathbf{Y}_1 \\ 
\mathbf{Y}_2 \\
\vdots \\
\mathbf{Y}_m
\end{array}\right),$$

then each $\mathbf{Y}_{ij}$ will be conditionally independent, or $\mathbf{Y}|\boldsymbol{\gamma} \sim N(\mathbf{X}\boldsymbol{\beta} + \mathbf{U}\boldsymbol{\gamma},\boldsymbol{I}\sigma^2)$.

Now we fit the model in `R`:
```{r, echo = F, eval = T}
library(lme4)
fitRI1 <- lmer(math ~ raven + gender + (1 | school), data = dataset)
summary(fitRI1)
```

* Compare the parameter estimates for `raven` and `gender` with the estimates from the linear model in a), and discuss.

We see that the parameters `gender` and `raven` (and the intercept) are larger for the random intercept model, and that they have smaller standard deviations. WHAT IS THERE TO DISCUSS??

* How do `gender` and `raven` score affect the math scores?

Again, we can say that for one female and one male student from the same school with equal `raven` score, the female student is expected to get 2.51119 better score on the math test. Also, if a student increases his/her `raven` score by one, we would expect an increase of 0.21442 to the math score.

* In the print-out from `summary(fitRI1)` there are no p-values. Why is this?

The distribution of the $\beta$s is assymptotically normal, but for finite sample sizes, the usual t-statistic is not t distributed. IS THIS CORRECT??

* Test the null-hypothesis $H_0:\ \beta_{\text{raven}}=0$ against $H_1:\ \beta_{\text{raven}}\neq0$ and provide a p-value for the test. (Yes, we have many observations and believe that we can calculate an asymptotic p-value even though the lmer package not by default want to report such a number.)

We assume we have enough observations to calculate an asymptotic p-value. We compute
```{r, echo = T, eval = T}
2*(1-pnorm(9.197))
```
We observe that we get an asymptotic p-value of 0 for testing the hypothesis $H_0:\ \beta_{\text{raven}}=0$ against $H_1:\ \beta_{\text{raven}}\neq0$. We reject $H_0$ and conclude that $\beta_{\text{raven}}\neq0$.

WERE WE SUPPOSED TO JUST USE THE NORMAL DISTRIBUTION??

* Also provide a $95\%$ confidence interval for the effect of the female gender on the math score.

We assume that we have enough observations for the $\beta$'s to be normally distributed. We can then compute a $95\%$ confidence interval for the effect of female gender to be
$$\beta_{\text{female}} \in [\hat{\beta}_{\text{female}} - z_{0.025}\text{sd}(\beta_{\text{female}}), \hat{\beta}_{\text{female}} + z_{0.025}\text{sd}(\beta_{\text{female}})].$$
And this gives
$$\beta_{\text{female}} \in [1.988, 3.034].$$

WERE WE SUPPOSE TO JUST USE THE NORMAL DISTRIBUTION??

# c)

We now continue with a random intercept model (school) with only raven as fixed effect (remove gender from our model).

```{r, echo = F, eval = T}
fitRI2 <- lmer(math ~ raven + (1 | school), data = dataset)
summary(fitRI2)
```

* Write down the mathematical formula for the covariance and correlation between response $Y_{ij}$ and $Y_{il}$ from school $i$.

We rewrite our model as
$$\mathbf{Y}_i = \mathbf{X}_i\boldsymbol{\beta} + \mathbf{1}\gamma_{0i} + \epsilon_i = \mathbf{X}_i\boldsymbol{\beta} + \epsilon_i^*.$$
We then write $\mathbf{V}_i = \text{Cov}(\epsilon_i^*) = \text{Cov}(\mathbf{1}\gamma_{0i}) + \text{Cov}(\epsilon_i) = \mathbf{1}\tau_0^2\mathbf{1}^T + \mathbf{I}\sigma^2$. This means that the matrix $\mathbf{V}_i$ will be on the form

$$\mathbf{V}_i = \left(\begin{array}{cccc} 
\tau_0^2 + \sigma^2 & \tau_0^2 & \dots & \tau_0^2 \\ 
\tau_0^2 & \tau_0^2 + \sigma^2 & \dots & \tau_0^2 \\
\vdots & \vdots & \ddots & \vdots\\
\tau_0^2 & \tau_0^2  & \dots & \tau_0^2+ \sigma^2 
\end{array}\right),$$
an $n_i\times n_i$ matrix with $tau_0^2$ on the off-diagonal and $\tau_0^2+\sigma^2$ on the diagonal. This gives

$$\mathbf{Y}_i \sim N(\mathbf{X}_i\boldsymbol{\beta}, \mathbf{V}_i).$$
In conclusion, we can say that the covariance between the responses $Y_{ij}$ and $Y_{il}$ from school $i$ is $\tau_0^2$, and the correlation is $\tau_0^2/(\tau_0^2+\sigma^2)$.

* What is this correlation for our fitted model `fitRI2`? Comment.

The `R` printout gives $\sigma^2 = 20.711$ and $\tau_0^2 = 4.002$, which gives a correlation of $4.002/(20.711+4.002) = 0.1619$. We observe that the correlation always has to be positive, because we only have square terms in the formula for the correlation. WHAT MORE IS THERE TO COMMENT??


* Write down the mathematical formula for $\hat{\gamma}_{0i}$ for your random intercept model and explain what the different elements in the formula means.

According to the module pages, it can be shown that after some calculations we get
$$\hat{\gamma}_{0i} = \hat{\mathbf{Q}}\mathbf{U}_i^T\hat{\mathbf{V}}_i^{-1}(\mathbf{Y}_i-\mathbf{X}_i\boldsymbol{\beta})=\dots=\frac{n_i\hat{\tau}_0^2}{\hat{\sigma}^2+n_i\hat{\tau}_0^2}e_i.$$

Here, $n_i$ is the number of observations in cluster $i$. $\hat{\tau}_0^2$ is the estimated variance of each $\gamma_{0i}$. $\hat{\sigma}^2$ is the estimated variance of $\epsilon_i$. Finally, $e_i$ is the average (raw, level 0) residual given by 
$$e_i = \frac{1}{n_i}\sum_{j=1}^{n_i}(Y_{ij}-\mathbf{x}_{ij}^T\hat{\boldsymbol{\beta}}).$$

* Explain what each of the six plots produced and displayed below can be used for (that is, why are we asking you to make these plots).

* Comment on your findings.


# d)

* Compare the model with and without the social status of the father using hypothesis test from the `anova` below (which is a likelihood ratio test - no, you need not look at the column called deviance since we have not talked about that). Which of the two models do you prefer?


* Why does the print-out say “refitting model(s) with ML (instead of REML)” (i.e. why do we not want REML when comparing models with the same random terms but with different fixed terms)?

* Also comment on the AIC and BIC of the two models (automatically added in the print-out from `anova`).

# e)

* Why is it not suitable to use a linear mixed effects model?


* What type of model would be more suitable? (hint: IL module 8)


* How would we add a random school intercept into this model (in which part of the model)?


* What is the main challenge with this type of models? (hint: marginal model)